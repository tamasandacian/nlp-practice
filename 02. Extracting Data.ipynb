{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we are going to cover various sources of text data and ways to extract it, serving as information or insights for businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The follpwing are covered in this chapter:\n",
    "- 1. Collecting Data from API\n",
    "- 2. Collecting Data from PDFs\n",
    "- 3. Collecting Data from Word files\n",
    "- 4. Collecting Data from JSON\n",
    "- 5. Collecting Data from HTML\n",
    "- 6. Parsing text using Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Collecting Data from API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of free APIs through which we can collect data and use it to solve problems. Here, we will mainly refer to Twitter API in particular since it contains a huge amount of data with a lot of value in it.\n",
    "\n",
    "When all of this data is collected and analyzed, it gives a tremendous amount of insights to a business about the company, product, service etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are needed for Twitter data analysis:\n",
    "- consumer key: Key associated with the application \n",
    "- consumer secret: Password used to authenticate with the authentication server\n",
    "- access token: Key given to the client after successful authentication of above keys\n",
    "- access token secret: Password for the access key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /home/dacy/.local/lib/python3.6/site-packages (3.7.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in /home/dacy/.local/lib/python3.6/site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/dacy/.local/lib/python3.6/site-packages (from tweepy) (1.2.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /home/dacy/.local/lib/python3.6/site-packages (from tweepy) (1.7.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/dacy/.local/lib/python3.6/site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dacy/.local/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/dacy/.local/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (1.25.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/dacy/.local/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/dacy/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "# install tweepy\n",
    "!pip3 install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials\n",
    "consumer_key = \"wTkUgbPZnCQBKXeZA4jv5KUoX\"\n",
    "consumer_secret = \"Z5hfLPvkyR49q7uFjUf4dDO9Hp65j3YqZ2WY1fHVYvo1GG9FG6\"\n",
    "access_token = \"706794838696574976-s8H9dItuWc1Z8xXakByhXgoSYC8qHha\"\n",
    "access_token_secret = \"RYUI34vZrdArHKigshrQlNQ4wq9inVvmpnDFaGPoRu1RV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling API\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the query you want to pull the data (e.g pulling data for the mobile phone ABC)\n",
    "query = \"ABC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching tweets\n",
    "tweets = api.search(query, count=10, lang='en', exclude='retweets', tweet_mode='extended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query above will pull the top 10 tweets when the product ABC is searched. The API will pull English tweets since the language given is 'en' and it will exclude retweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Collecting Data from PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time data will be stored as PDF files. We need to extract text from these files and store it for further analysis. In this part we will make use of PyPDF2 library and see how we can extract data from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /home/dacy/.local/lib/python3.6/site-packages (1.26.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install required library\n",
    "!pip3 install PyPDF2 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this exercise, I will import a personal pdf file from where I will extract text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pdf file object\n",
    "pdf = open('./data/pdf/Text Classification on Social Media Bachelor Thesis.pdf', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pdf reader object\n",
    "pdf_reader = PdfFileReader(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of pages in the pdf file\n",
    "pdf_reader.numPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a page object\n",
    "page = pdf_reader.getPage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U\\nNIVERSITY\\nC\\nOLLEGEOF\\nN\\nORTHERN\\nB\\nACHELOR\\nT\\nHESIS\\nTextonSocialMedia\\nAuthor:\\nDacianTamasan\\nSupervisor:\\nHenrikKristianUlrikllgaard\\nAthesissubmittedinoftherequirements\\nforthedegreeofWebDevelopment\\nin\\nJanuary20,2019\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally extract text from the specified page\n",
    "page.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the pdf file\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Collecting Data from Word files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will take a look into how to extract data from Word files in Python. For this we will make use of docx library in Python.\n",
    "\n",
    "We will use as well a personal doc file to extract data from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in /home/dacy/.local/lib/python3.6/site-packages (0.8.10)\r\n",
      "Requirement already satisfied: lxml>=2.3.2 in /usr/lib/python3/dist-packages (from python-docx) (4.2.1)\r\n"
     ]
    }
   ],
   "source": [
    "# install required library\n",
    "!pip3 install python-docx --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required library\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a word file object\n",
    "file = open('./data/docx/TrustCo System - Analyzing Reviews Report.docx', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a word reader object\n",
    "document = Document(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty string and call the document.\n",
    "# document variable stores each paragraph in the Word document. We create a for loop that goes through \n",
    "# each paragraph in the Word document and appends the paragraph.\n",
    "doc = \"\"\n",
    "for p in document.paragraphs:\n",
    "    doc += p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"University College ofNorthern DenmarkTrustCo System Analyzing Reviews from Amazon\\t\\t\\t\\t\\t\\t\\t\\t                                                        Dacian Tamasan, Curcuta Lucian \\t\\tdmai0914, Computer Science\\tTable of contentsIntroduction.............................................................................................................................................4Problem statement ..............................................................................................................................4Project Learning Goals................................................................................................................................5Crawling Data from Amazon................................................................................................................................5Domain Model.............................................................................................................................................6Relational Model.............................................................................................................................................7Architecture.............................................................................................................................................7Implementation..............................................................................................................................................10Working Process..............................................................................................................................................156.1 Sprint 0 ...................................................................................................................................196.2 Sprint 1 ...................................................................................................................................246.3 Sprint 2 ...................................................................................................................................316.4 Sprint 3 ...................................................................................................................................396.5 Sprint 4 ...................................................................................................................................486.6 Sprint 5 ...................................................................................................................................56Learning Outcomes & Future Work.............................................................................................................................................58Conclusions.............................................................................................................................................60Appendix.............................................................................................................................................61IntroductionProblem statementE-commerce websites are only going to become more popular as time passes. With technology progressing the way it is, more and more people will shop online. More and more people realize how convenient it is to do shopping online, particularly when they are looking for different products that are not easy to find in their local area.Nowadays, most of the customers read a lot of information regarding a product in order to get an insight on the actual quality status. We all know what reviews are and we all know how important reviews can come in taking the decision of buying a new product. What is really hard to find on the Internet is a Website that can show how trustful can be a product, and how this can influence the customer’s decision in buying a product.  Since this area covers a lot of research, our project idea evolves around product’s reviews. Therefore, we decided to create a Web Application which analyzes a large amount of data from one of the most popular E-commerce Website, and by presenting to the user the most useful and relevant review will help in taking the right decision for buying a product. In addition, our proposal technique is the first step towards preventing fake product and fraud which has a huge impact on economic.We want to collect and analyze data from a popular E-commerce System such as ‘Amazon’, we want to collect product’s data together with reviews data. To the best of our knowledge there is no existing system that address the problem of fake and low quality review. Therefore, as a result, we want to display an aggregated score based on the review that the customer posted on the page.The score set for the product’s review will be stored in the database together with a huge number of reviews. This will lead to a better response time when a new user will search for a product’s review.We intend to show a small number of reviews collected and all of them will show a collection of positive and negative reviews for the customer on the page.Since our idea is all about products and reviews we would like to implement a search which will help in retrieving all the information of a product and product’s reviews. The user will be also able to search for different products based on categories, and all results that are shown will help in understanding if the product is trustful or not.  Project Learning GoalsReaching project goals equates to project success. But in order to achieve goals we must first have to define them clearly and then support them with an action plan of well written objectives. By doing this, we will achieve a successful project outcome.Some of the goals that we wanted to achieve during this project are as follows:Create a Web Application using Spring MVC Framework Integrate Apache Tiles an open-source template framework for modern Java applicationsGive alternatives for user in querying data such as ability to search for different categoriesAdd a level of security for Register and Log in within the webpage.Use query optimization within the database for better search results. Crawling Amazon DataAt the beginning of the project after doing a brainstorm and when both of us agreed on the problem formulation for the final project of Academic Professional Degree we looked on how to get information from Amazon website and how it can be useful the processed data for all users.We started digging into understanding terms like crawling and scraping data and after some research we found out that scraping Amazon data would be useful for different things. By scrapping data, we could analyze Amazon reviews of different products from the website, we could analyze Amazon marketplace Sellers, monitor an item for change in price, analyze the stock, rating and many other things. After looking into the website and analyzed in detail how all processed reviews are compared, we came to a conclusion that it would be a good idea to aggregate into a score a plenty of positive and negative reviews and display the score on the page into a percentage.The easy way of how to get started with scrapping Amazon is by building a crawler in Python or Java. We looked and tried to find an example and start crawling data as soon as possible so that we could use data in our database and to manipulate as how we wanted. Later on we found out that this crawler can go to any of Amazon product’s page using an ‘asin’ (amazon keyword for tracking products in its database). This keyword having both numbers and letters and this one representing the connection key. We had to decide the format of how to get the information in XML or Json format. Then we started using one of the code provided from GitHub and used to see how much time does it take to collect data. The time was not suitable for us and we realized that after our calculation it will take between 3-4 weeks which would not bring us anywhere with our idea and we would be forced to change the plan in a short period of time. Looking on the Internet we found old data collected from 2013 by some developers, Amazon data used for research in Json format and this would help us a lot. Since we knew how to use Amazon API and how to collect data we decided to work with existing data for both reviews and products.Domain ModelThe Domain Model is a representation of real-world conceptual classes, not of software components. It is not a set of diagrams describing software classes, or software objects with responsibilities.”Domain Classes: Each domain class denotes a type of object. Attributes: An attribute is the description of a named slot of a specified type in a domain class. Each instance of the class separately holds a value.Associations: An association is a relationship between two (or more) domain classes that describes links between their object instances. Associations can have roles, describing the multiplicity and participation of a class in the relationship.“The domain model is an important part of the working process. It represents the classes in the current program, the information about these classes in pattern of attributes and it shows the connection between them as well. It is in a use from the software developers to show the future software.(Figure 2.1 Domain Model)As we can see in figure 2.1 our domain model does not have so many classes. Since this area covers a lot of research that had to be done, we designed a simple architecture where everything had to be simple and effective.The relation between Review and Product is one to many where a Review can have only one Product and a Product can have many Reviews. The Review class contains a set of attributes where a part of them: reviewerID, asin, reviewerName, helpful, notHelpful and reviewText were used to come from Json file (review’s data collected from Amazon) when data was parsed from Json format into variables while positiveCount, negativeCount and finalScore were added later in our project in the Review class with the scope of aggregating a score for all reviews.However, positiveCount, negativeCount, and finalScore are used in the JsonParser class in the analyzeSentences () method for the analyze process, and then to be sent into MySQL database into Score table. The reason why we needed to add these variables into objects is so we can carry on more data since in the table we had to handle 50.000 objects of review type. So adding this extra variable were necessary in order to achieve our objective.The Product class it also contains a set of attributes where a part of them: asin, title, price, imgUrl were used to come from Json file (product’s data collected from Amazon), when data was parsed from Json format into variables, while categories represents an Array List of Strings and represents the category that the user will choose from the Java Serve Page.Relational Model(Figure 3.1 Relational Model)The Review Table stores data about reviews and is connected with the Product Table through the asin column. The relation between the Review and Product states that a review cannot exist without a product. The Product table stores data about products and the primary key is asin. The relation between the Product Table and the Review Table states that a product can have one to many reviews. The Login Table stores data about customers and the primary key of this table is email.ArchitectureSpring MVC Framework takes the path of Model – View – Controller and is a well-known design pattern for designing UI based applications. The main core of this framework is that decouples the business logic from the View by separating the roles of model, view and controller in an application. In this pattern, the model is responsible for encapsulating application data for view to present. The View which in our case is Java Server Page should present data without including any business logic.And the last one – the controller which is mainly responsible for receiving requests from users and invoke in the back-end dao and service layer for business logic processing. When the process is done, the service will return some data for the view to present.  The controller collects this data and prepare the model for view to present. We have chosen to work with Spring MVC Framework because this framework helps in separating the business logic from the View, it also allows to change them independently without affecting each other.It provides rich functionality for building robust Web Applications. This framework is designed in such a way that every piece of logic and functionality is highly configurable. More than that Spring is not tightly coupled with Servlets or JSP to render the View to the Clients.As we can see in the figure below, we have illustrated the architecture of our Web Application where the model layer is represented by the DAO (Data Access Object) while the Controller takes all services and the View which is represented by the Java Server Page in connection with Apache Tiles through header and footer and the body content.Looking at the architecture in the first layer DAO (Data Access Object) layer we defined and created a set of interfaces that abstract data of different entities. What exactly does this layer is that separates low level data accessing API or operations from high level business services. Inside the interface we defined the methods that we want to use for specific entities and in DAOImpl classes, the implementation of all methods. The implementation translates the underlying data model into a canonical representation, in general entities or data transport objects. Here all the process is taken by the dataSource object which in fact can be found in the dispatcher servlet (spring-servlet.xml) and this one makes the access with the database by doing different SQL operations (insert, retrieve, update)(Figure 4.1 Spring MVC Architecture)Benefits of using Spring MVCIn this section we will make a general comparison with existing frameworks from Java where we will state the advantages that Spring MVC has on top of the other frameworks and the reason why we chose to work with it.At the beginning when we had our idea, we looked into a framework that we can use and one that suited to our needs. We found out that there are many frameworks like: Spring MVC, Struts, JSF and many others After doing some research and looking into all frameworks that could be used in Java for developing an Web Application we found that the majority of all developers voted in favor for Spring MVC Framework.We could not make a general comparison with all existing framework, for that we took only two popular frameworks and put them side by side. For this part we will talk in general all differences between Spring MVC and Struts framework, two of the most usedOne of the main advantages of Spring MVC is that can be integrated with many view options such as JSP/STL, Tiles, Free Maker etc. which means that is not dependent on a particular View. Unlike Struts, Spring MVC does not provide AJAX support where is needed for third – party AJAX library.Spring MVC framework provides a clean division between layers in the model, view, controller while using Struts framework we would not have the same. Both frameworks are considered highly mature, and choosing one of these will come to personal preference. We have chosen to work with Spring MVC because this framework can be integrated with other view technologies and because it has a well-defined architecture.Architecture when using Amazon APIWe have made a sketch with the architecture if this one would have been changed when using a public API.As we can see in the figure bellow the first part shows how the information is taken from the Amazon API, and then stored as a collection of reviews so that later can be processed into JSON, XML/HTML format. After this process the review information is stored into database the first time and then made an analyze of positive and negative words. Based on the analyze all scores are stored in the database. In the second part we explained showed the process when the user will query in the Web browser for a particular product. When searching for a product a score together with reviews will displayed on the page. (Figure 4.2 Spring MVC Architecture Accessing Amazon API)ImplementationWe started off by putting down on papers different architectures for the webpage and trying to come with simple versions, not to fancy or overly complex. We wanted an architecture as simple as possible because if it was something that we learned in the previous projects is that in order to have a good website you need to keep it simple so that was our objective. So after a lot of drawings we both came to an agreement on what we should keep and what we should throw away.(Figure 5.1 Website Sketch)We wanted to do it easier by putting all things that we learnt so far by doing a Web Application and using a free template from the internet. In the first Page we have some text that would summarize the role of the webpage and some information under the title of the page so that the users can see and understand what exactly is doing our Website.In the second page which in our case is Trust page, we decided to have a textbox where the user will input and search for a particular product together with a dropdown list, giving the user the freedom to search for product’s review on different categories. We would like to make this in a such way so that when the customer will type a word in the search box a hidden table will be shown with all positives and negatives reviews. The customer then in order to distinguish if the product is trustful or not, when searching for a product, a bunch of collection of positive and negative reviews will be displayed together with a score in percentage. The score will be displayed into an appealing form such as a star or a circle or something else that can be quite descriptive and informative for the user.Why use Bootstrap? Bootstrap is an excellent CSS framework that provides many carefully crafted user interface elements, layouts, and jQuery plugins. Bootstrap is open source and is also one of the most popular projects of all time on GitHub. Bootstrap contains a top-notch, responsive mobile-first grid, which allows you to implement your design in a breeze; it comes with ready-made styles for typography, navigation, tables, forms, buttons, and more. Bootstrap also includes some jQuery plugins, such as Modal, Dropdown, Tooltip, and Carousel, which come in handy quite often. Today, you can use Bootstrap to throw together quick prototypes or guide the execution of more sophisticated designs and larger engineering efforts. In other words, Bootstrap is a very simple way to promote quick, clean and highly usable applications. – Mark Otto, creator of BootstrapBootstrap works on all the latest desktop and mobile browsers. While older browsers may display Bootstrap differently with respect to styles, it is still fully functional in legacy browsers such as Internet Explorer 8.We are using Bootstrap in order to give the webpage a more dynamic design that could adapt the customers’ needs and also being able for the webpage to be viewed for the customers on the smartphone or even under the same design as it is on the webpageTrust Page (Figure 5.2 Trust Page Part 1)In this page the customer has to input a word in a textbox and to press the search button. This search box will also help the user in query data such as when the customer wants to write a word, after just 2 or 3 letters a word will be displayed inside the textbox. In the middle of the content, a box with the product name together with all reviews will be displayed. All reviews will be separated, we were thinking before to have in the left side those that are positive and in the right side those that are negative. Since this approach was quite hard to adopt, we used to have in the middle displayed the product name and on each row two or three reviews at a time displayed.In this part all reviews will have their own section with like and dislike sign and assigned a score for each of them. All scores are represented into a number and are made based on analyze of a dictionary of positives and negatives words. For this approach we used two different files, one file that contains positive words and another file that contains negative words. The aggregating score of each review has been made on an analysis, where we checked how many times a positive or negative word has been occurred into a Review text. Based on the analysis made we aggregated also the final score for each review. At the bottom of each review a score in percentage will be displayed together with a small description which inform the user – the actual status of a review. The final score was made on a sum of all positive and negative reviews, and then checked into a comparison of which has the higher number between positive or negative. For instance, if positive is greater than negative than the score will be made on a simple math formula and then displayed into percentage. We used the same approach for the other part when comparing if negative will be higher than positive number. Based on the final score the customer will have more insight and will be able to understand if the product is trustful or not. The higher number will be more than enough to understand if the product can be bought or not. Other feature that we wanted to have here is to give alternatives for users when looking for a into the search bar the user can also query with the help of a dropdown list. The selection can be made for different categories such as: likes, dislikes, shortest, longest, positive and negative. When selecting one of these categories the information regarding reviews will be displayed exactly for what the user is looking for.   (Figure 5.3 Trust Page Part 2)Register and Login PageIn the Register Page the customer has a number of text boxes where he has to insert information and afterwards press the Register button. What this does is that is saves the customer’s information’s in the Database and redirects the customer back to the Log in page.In the Log in page we have 2 textboxes with 2 placeholders where the customer will have to insert his email address and his password. When the customer presses the Login button he is remembered in the webpage as logged in and in every page on the website the Hello + the customer email address will be displayed. When the button Log in is pressed a session with the email address is created and passed to all pages in the navigation bar. Another aspect is the fact that if the customer wants to have access and receive more information regarding products based on all reviews, the customer has to be registered and logged in into the website.(Figure 5.4 Register & Login Page)Momentarily we use Sessions for the Login which makes it possible for the customer to login and stay logged in for the time he\\\\she is browsing the website. After the customer is logged out automatically because sessions are voided after the user stops browsing the website.We wanted to use Cookie for the Login part. In this way when you want to login you will be logged in until you log out. We want to use a”. expire” action on the cookie which will void the Cookie after a period of time. However, this approach will take care of the login part for the local hosted version of the website. Working ProcessIn the beginning we created a sketch on paper of how it had to look our website, to have an idea for the start. After that we did a plan with all tasks that needed to be solved.  All tasks can be seen as bellow and were emerged into Sprint Development.(Figure 6 a) Table Sprint Backlog)Every day we allowed 10 minutes for a short conversation where each of us had to present the work that we did the previous day. As well when one of us got stuck we decided to analyze the problem and to work together on it, but this was not big deal since we worked mostly all the time in the library and at our place where we helped each other. At the end of each day we used to have a small recap where we explained one more time the whole work in order to keep tracking and be in time with all of the tasks. Adopting this method was a very good decision because we were able to solve most of our problems in time.In the beginning was quite hard with our meetings because Dacian had to be also in the Internship due to the fact that he had to start his Internship later. However, we tried to keep in touch with all the tasks that we planned at the beginning and if one of us could not do or was stuck then one of us would take a look before into the problem.  We decided to meet every day from Monday until Friday after 16:00 at the library or at our place. If one of us is unable to show up for legit reasons, we had a Skype conversation where we talked about a particular problem that we had to solve. We used also Facebook as a way of communication where we discussed where to meet and work. In some days it was almost impossible because we had to work, having both of us a part-time job, Dacian working in the hotel during the day and Lucian working in 3rd shifts.Every piece of the project should be made by all of us so that we could understand what is going on and nobody feels excluded. We should discuss everything and we need to make sure that we agreed with the “blueprints” before we started working on the project.Last but not least, everyone should be responsible, work hard, and give their best in order for this project to be successful and the most important thing is that everyone should understand every part of the project.(Figure 6 b) Table Task Board)6.1 Sprint 0We wanted to have a smooth flow in the development process and in order to achieve that we decided to take on sprint 0 as an accommodation sprint. What this means is that in this sprint we were mainly focused on setting up the Spring MVC Architecture, creating the Database and lots of research because the implementation of the architecture is an unknown field and in order to manage and to gain productivity we needed to start building the structure.We did a lot of research, to have a better understanding of the architecture, to understand how is layered, how is represented Spring MVC (model – view - controller), the relation between client and server and so on. The estimation was a big part of the Sprint 0. We couldn’t estimate everything in our project but we had to do this especially if there was a cost of delay that justifies it.The first thing that we have done was to create stories which represent the functionality that we wanted to implement in our project. Then we put all the stories into Sprint Backlog, we analyzed each story and created tasks which needed to be done in order to achieve the functionality. We estimated the necessary time in order to complete the tasks and specified who will be in charge with the task given. Sprint backlog is a model in which the stories are stored in a prioritized manner followed by another column which represents the tasks that are meant to be done, in a story sprint, in a prioritized manner. The sprint Backlog does not contain only stories; it can also contain tasks that the team needs to focus on. The Owner Colum of the model ensure that each task is assigned to a team member. This makes the whole process more organized. Each programmer takes a task and updates the Sprint Backlog. The last column of this model is called “Initial Time Estimated” and the purpose of this part is for each programmer to estimate how much time it is expected from them until the task will be completed. However, this part is not reliable when new technologies are involved. Since this field is unknown, a lot of “exploration” is done before the feature will be finished.Here is the vision of the Sprint 0:  (Figure 6.1.1 Table Sprint Backlog Sprint 0)We estimated each story at the beginning because in this way we’ve had an overview of the whole amount of work that had to be spend for a single story. Once the estimation was made we couldn’t change it anymore.In this sprint we set up a meeting where we took a step back and looked overall at all the tasks that we had to accomplish in the Sprint. We took our time and discussed about the framework, layout and the database and what information is needed to be stored. At this stage and in Sprint 0 we mainly started first to understand the framework and to build the template for our Web Application and later on to create the database in MySQL.Since we have decided to take the project in a different architecture by choosing a different programming language, we decided to take it slow in the Sprint 0 so that we can get acquainted with the process. We decided to develop our project in Java by using Spring MVC as a Framework. At the beginning we looked into Spring MVC Hibernate and tried to understand the framework, to see how all classes are connected and so on.  However, after a while we decided to switch from this framework and look for another one such as JDBC framework since both covered the database processes. We found Spring MVC Hibernate way harder to understand and even though we tried to get our minds around the concept behind it, we just came to the same conclusion that we should not work with it.The reason why we chose to stop working with this framework was because we couldn’t find the syntax helpful, and because all SQL statements were different than what we used before. So after a little bit of research we found Spring MVC JDBC framework to be self-explanatory and more optimal.JDBC Template provides an efficient mechanism to deal with database, no need to bother with XML configurations or write the same code again and again as in traditional JDBC programming. The configuration regarding MySQL database is specified in the spring-servlet.xml file and JDBC Template finds quite really easy the access to it.Another pro of this framework is that provides also a better error detection mechanism which splits the JDBC SQLExceptions into Runtime Exceptions.A couple of days later, we found that is not a big difference in using JDBC Template library compared to Prepared Statement library when inserting or retrieving information from the database and nothing is different in the XML configuration files. Since it was not a big difference, we changed in a such way to use the same approach and in the same way as how we learnt in the University. By using a clean and understandable code we could save time and we could increase the working speed. When we finished with the first task, by preparing the Spring MVC Framework, we took a look into a template that can be used for rendering the header and footer.Apache TilesDuring the first Sprint we tried to come with different solutions for making the layout working and not to repeat different parts of the code in the View. Because we used in our last project in Visual Studio C# - Master Page as a template, we were quite sure that we can adopt the same methodology also in Java.Another reason why we wanted to use a template it was because we realized that using and repeating the same code will make the Tomcat Server complain when running the program and the information would not be displayed since we are duplicating the code. After doing some research we found out that there are some frameworks that can be used and can make the code working without complaining such as: Thyme leaf, Mustache, Struts and Tiles. We tried some of them but we didn’t succeed until we found that using Apache Tiles is easy to understand and to work with.  What is Apache Tiles? Well is a free open-source template framework for modern Java applications. It allows to define page fragments which can be assembled into a complete page at runtime. These fragments can be used really easy and avoid duplication of common page elements. Another factor is that we can reuse these fragments in all of our pages without writing or changing the code.We tried in the beginning to use the latest version of Apache Tiles 3 but we didn’t succeed right away. The first think that we did was to put into a XML file “tiles.xml” all the configuration for all pages that we used. The file looks as how it is shown below: (Figure 6.1.2 Integration Apache Tiles Configuration)In the first part of this configuration we can see how is used the main template to be as part of each page. All pages are connected to this template and by using the keyword extends of the template will make the header and the footer shown on the page. We knew that we have almost everything in our code, all the configurations, all files but something was missing… Then we looked into Stack Overflow and checked what we have missed or why it doesn’t access the file that it was supposed to come with this framework. Then we found some explanations where using the definition name on top of the Java Server Page will make the page render the header and footer. We tried to use the same code in all our pages but we knew that is not the right way. Why? Is because when the user will be logged in he won’t be able to see if he is really logged in the website, when looking into other pages which leads to a big mistake.Looking in detail and trying over and over again many examples we decided that we spent a lot of time on implementation and we should try the older version of this framework.  So, we took the another version, and older version, and in order to make this framework working the first thing that we had to do was to define all the libraries that are corresponding to Apache Tiles 2 in POM.xml. This framework was supposed to be a bit different because in spring-servlet.xml file we had to remove all configurations with all. jsp prefix and to make it work exactly for Tiles 2. The second part was to define in spring-servlet.xml file bean properties for it and we used the same code in tiles.xml. The configuration file is located in WEB-INF/tiles.xml The configuration spring-servlet.xml file looks as bellow: (Figure 6.1.3 Apache Tiles 2 Configuration spring-servlet.xml)Inside the file we defined through <tiles-definitions> tag the template and all attributes that we want to use in our pages. All these attributes represent fragments and can be reused in all. jsp pages. We needed only the header (navigation bar) and the footer where the body can be filled and changed at any time. After configuring and connecting all these parts we ran the program and we realized that all pages that we are using are rendered and displayed exactly how we wanted. An important role in displaying and rendering CSS, JavaScript and Images in Spring MVC is represented in the line 64 of this configuration file. Here is specified the path and where all this files are located.At the end of the Sprint 0 we have adopted Sprint retrospective where we had a small discussion based on what we did in the Sprint.Sprint RetrospectiveWhat went well?We managed to stay on track with the Spring MVC Framework and Apache Tiles and have a better understanding of what we were doing, how all layers are connected and what we have to do in the next step.We held a Scrum Meeting on a daily basis which helped us to keep tracking of what is going on.What could have gone better?Like it is mentioned in Sprint 0 we had some problems in understanding the framework since Spring is coming with different development frameworks such as: Spring Hibernate, Spring MVC, Spring JDBC, etc.However, this problem was shared within the group since both of us had to understand the framework and how the project has to be developed.Any surprises?We were surprised with the fact that every member of the group managed to make its own task on the set date. We think that this is due to the Scrum meetings and the Task board which were in our big favor.As we finished with this task we started looking into data that was collected from the Amazon and afterwards to design a simple database for our Web Application.As a conclusion for Sprint 0 – everything went well and we had a smooth development with a day off since both of us had to work in that day.(Figure 6.1.4 Burn Down Chart Sprint 0)6.2 Sprint 1As we started the Sprint 1, we mainly focused around processing data that we took from Amazon and we parsed data in a format that we can use in order to migrate it into our database. Our next goal was to make an analyze on the review’s description so that we can process a score which will represent the quality of the product’s review.As we mentioned before we set up a level of priority of each story at the beginning of our project and we came to the conclusion that in this Sprint we had to parse data from the Json file which was collected from one of the most and well known E-commerce shop – Amazon. Here is the vision of the Sprint 1:  (Figure 6.2.1 Table Sprint Backlog Sprint 1)Because we knew that our time is limited and we couldn’t cover all topics in our project in a short period of time, we decided to take all data collected from a Website with the help of other developers so that we can start working on our project as soon as possible. All data provided on the Website came in a large Json file format. In order to accomplish one of our main task, we took from this Website two different files the metadata.json which represented all product’s information and another file representing all reviews of all products.The first thing what we did, we took these 2 files and tried to open them in Visual Studio. Apparently for one of these files such as for review’s data we could see all the information in Json format. However, we found out that we have some restrictions in opening a file. For all files larger than 5GB we had to find another way of how to read data. Unfortunately, we had to work with metadata and this file was even larger than 10GB. After doing some research we found out that using Cygwin (a large collection of GNU and Open Source tools which provide functionality similar to a Linux distribution on Windows) we had the chance to read one line from the file and this was quite enough for us and helped us to know how the information is disposed inside. We could also read one line with Command Prompt by using the command “more” but in the end we used Cygwin because is way more affordable and we can use quite easily for what we wanted.After having the first line from metadata file, we copied and put into Json Formatter Online to display all the information in a more understandable way. One of our biggest challenge in this Sprint was to map all reviews for products. At the beginning it didn’t look like a difficult task but we didn’t know that from the multiple resources that we can use there will be a file that has review for each product, and until then we tried mostly all of them. Moving on with our task we found that the product ID of a product from the metadata file was called ‘asin’. Afterwards we tried to find the asin in all reviews files so that we can find a match between product and review. Again by using Cygwin we didn’t even have to open any Json file because this software is powerful and helped us to retrieve all reviews of a product by querying on the same asin. Once we knew all these details, we knew what we have to do for the next step.(Figure 6.2.2 Cygwin – Retrieving a product based on ‘asin’ of a Review)We looked which information we have to store in the database from these files and we created two tables in MySQL database one table for Product and another one for Reviews since the project is based on reviews. When we created the database we agreed that we want to have a simple and functional database so that we can move on and make sure we don’t have to come back and change the database again. So, we started to do a simple Java program and we created a simple Java class JsonParser, having the connection set up for the MySQL database. Then we have built methods which help reading and parsing data from the json files. For this approach in this class we created two methods one for products and another one for reviews, that reads data from the files. We used the BufferedReader library to read line by line information from these files. After reading data from the files we parsed the information and stored into a String, and then we prepared data to be sent to database. Everything went well until inserting reviews in the database when we had some errors, Java program complained that for some reason at a certain line, the code would collapse because Json file couldn’t be parsed correctly of a different set of characters. We tried to debug and look into the problem until we realized that this is not a big problem and we can make in a such way so that it can skip at this line of code. After skipping this part, the code worked and we decided to let this part for the moment, and come back later to fix it because we realized that this is not a big issue and we can move on. At the end of the Sprint, after seeing that we can retrieve information from MySQL database based on asin, we decided to postpone the searching part until we get more insight with Spring MVC and how all classes are connected.At the end of the Sprint 1 we have adopted Sprint retrospective where we had a small discussion based on what we did in the Sprint.Our project main subject is data analyzation and we manage to do that in the JsonParser class.The process that we follow in order to make the analyze is at follows. First, we need two lists in which we store words which represent words that might be commonly found in a positive/negative review. We gathered a big amount of words that might be usefull to the cause and we stored them in a .txt file .What we do next is that we create two  strings which store the directory where this .txt files can be found ,we would use this later.(Figure 6.2.3 Dictionary of positive & negative words)Now what we do is that we create 2 array Lists which will hold strings and we call the method which will read the files and insert the words in the Array List and in the method we pass the String that we have created earlier.(Figure 6.2.4 readPositiveWords () Method)In this method we use the Buffer Reader library to read from the .txt file word by word. Then we create a while loop in which we set the String value lineText to be equal to the first word from the txt file and we then set the word in the Array List. We loop this process until there are no more words in the txt file.Bug Alert.We have identified a bug which will slow the analyzation process because if spaces are left between words instead of having each word on a new line then the line would be saved and it would mess up the whole list because it would have an empty string, this is because he buffer Reader reads the .txt file line by line.(Figure 6.2.5 readPositiveWords () Method)Now that we have the list of positive/negative words we need the review so what we do I that we create an array List of reviews and we call the getReviewText () method which will take the data from the database and store it in the Array List and return it when there are no more records in the databases.In the analyze phase we create an array List of review and on this list we call the analizeSentences method and we pass the positive list, negative list and reviewsIn the first phase of the method we analyze the reviews based on the positive word list.(Figure 6.2.6 analyzeSentences () Method)What happens here is that we firstly start by looping trough reviews and getting the reviews one by one. Then we create a new string in which we take the review and we put in the lower case the whole sentence so that we would have problems with lower case or high case words.Then we set a count which will represent the amount of times a word from the positive Wordlist has been found in the review sentence, since the count is outside of the loops that are to follow, the count will not be reset until when the next review will be taken. By doing this we will have the review and the count and what we will do is that after we are done with the analyze we will update the review object with the resulted count.Further on, we have another loop where we loop trough the positive word list and we take one word at a time and then we keep create an int lastIndex which will store the position in the string, this is implemented earlier in the code so that the value would not be reset until we move on with the next word from the list.Next we have a while loop in which we check if the lastIndex value is not -1 if not then we loop trough the sentence with the word, and when we found the word we update the lastIndex to know where the word was last found.Lastly we have an if where we check again the index of the lastIndex and we increase the count if the lastIndex value is not -1 and afterwards we set the lastIndex to the int value of where the word was found in the string. In this way the code will go through the whole review sentence and when it will reach the end of the sentence the index will be -1The process repeats for the negative words list.(Figure 6.2.7 analyzeSentences () Method Part 2)In this part we set up a loop in which we take the positive and negative value and we sum them together. Afterwards we check to see which value is higher, posScore or negScore. In the case where the negScore is bigger we take the create a variable in which we calculate the percentage of how negative is the score base on the sum. Basically we divide the negScore with the Sum and then we multiply it by 100 and by doing this we get the percentage of how negative is the review. Then we create a new variable in which we get only the first 2 digits from the percentage variable. We then store in review object the percentage and since we passed through the if statement we know that the negScore is higher so, we know that there are more negative words then positive so we create a string which will contain the text definition of the review. We will use it later when we want to display the status of the review.For the cases where the count is equal we just update the review with the String Value Equal. When no words have been found from the 2 lists (positive and negative), we just update the review object with the string Neutral.(Figure 6.2.8 insertReviewScore () Method)In the last part we take the data that we needed from the review list and we store it in the database using the executeBatch () methodSprint RetrospectiveWhat went well?We managed to finish all the tasks that we set up at the beginning of the Sprint 1.What could have gone better?It would have saved from our time and increased our productivity if we would have had the right information collected from Amazon.Any surprises?We had some issues in parsing Amazon data, in parsing product’s data from Json file. We had some issues in inserting reviews into database, where Java complained that does not exist review for the product.Changes needed for the next sprint?Not for now since we managed to find the right Json file for reviews and insert into the database.(Figure 6.2.9 Burn Down Chart Sprint 1)In sprint 1 we managed to be more productive than we expected in the first days and since then we managed to have a linear progress. However, after a few days of productivity we realized that the data that we took from the amazon website was incomplete therefore we had to turn back to the amazon’s website and find the reviews which match with the products that we have initially took. Afterwards we focused on our objective and we started developing intensively and we managed to have a good productivity, better than what we have expected. On the 4th of December we both took a day off from work since both of us were buys with our jobs and afterwards we kept working and we managed to finish in the expected time.6.3 Sprint 2In this Sprint we were mainly focused on the Register part and for that we took our time and looked how to implement it. Here the estimated time for the task is not accurate since everything could go in the wrong direction, which means that bugs and errors could slow down the process or it could go into other direction, meaning that we could manage to have a smooth developing process without any errors or bugs. That is why the time set for this Sprint is higher than the standard one that we use per task so that we can manage to handle the developing process.Here is how the vision of the Sprint 2 was:  (Figure 6.3.1 Table Sprint Backlog Sprint 2)We took our time at the beginning of the Sprint 2 in order to Design the UI for the Page that we are developing and then we built up the MVC Structure for Register starting with coding the classes specific to each layer until we reached the Controller class. Afterwards we coded the webpage based on the UI that we have Designed in the beginning of the Sprint and then we added the Input Validation to the page in order to handle situation when the customer forgot or did not input his information into the register form. When we were ready with the implementation, we did tests in order to ensure that the process we followed was as how it was expected. When we were done with the Sprint we took our time and split the task that were meant to be done, to put them into the report.In this part we decided to use one of XP's practices which is Pair Programming so that we can both of us put our minds together and figure it out the architecture and how to code certain parts of the task. For example, one of the biggest change was the Controller and the. jsp files, that is because each webpage needed to be registered in a Controller and we also needed to configure the path of the URL. All these. Jsp suffix format of the files are exactly the same as .html and represents the View from MVC where M-model, V-view, C-controller. Also in order to get data from the. jsp textboxes or display data in them we needed to wrap them into a <form> where we had to assign an action and a method. For this we needed some time to get acquainted with this practice.We have had multiple 404 errors while trying to redirect the link to the webpage or while trying to take data from the jsp file when the register button has been submitted. The problem with the redirect was sometimes because of typo errors or since we have not formed the correlation between the link and. jsp file correctly. In our defense, there are multiple forms in which you code the redirect but some would work, and some would not. We also encountered some random errors where the code was good, however the program showed error and in order to fix this we eventually closed the Eclipse program and reopened it and the error disappeared or we updated the project through Update Maven Project option from Java Eclipse. Register Method Implementation:(Figure 6.3.2 registerCustomer () Method)In order to create the Register Method, the first thing that we did was to create in the Model layer the Customer class. Afterwards we created a package called dao and defined into an interface all the methods that we wanted to use. In this part we will show only the relation between classes and the method that saves a new customer into the database.  The implementation of the register method it is straight forward and easy to understand. We took the method that we specified in the interface and then we expended the implementation of the method in the CustomerDAOImpl class.As we can see in the figure 5.3.1 in the registerCustomer () method we created an insert SQL Statement where the information is saved into the Login table from MySQL. The Login table will have strictly information regarding email and password since the system doesn’t need more information stored regarding customer’s information. This part with the register should not be hard and it wouldn’t take so much time to implement it. At the beginning we tried to make it work, to see that the information it will be inserted into database and afterwards we added a level of security. Looking at the code in the try – catch block, we have opened the connection through dataSource.getConnection() and then we passed email and password’s information with the help of “pstmt” object of PreparedStatement library through the executeUpdate () method. The next line specifies when the transaction is starting through the commit () method. If something wrong happens then it will be thrown to the catch block and the transaction will be rolled back. Then we check if the prepared statement object is not null, and if is not then we stop the insert statement again in the database. We did the same approach for the connection where we check if the connection is not null, and if is not then we stop the connection.Afterwards, we created a new package called services and inside an interface CustomerService representing the interface of the service and a class CustomerServiceImpl representing the implementation of the method. Inside the CustomerService we defined the method and inside CustomerServiceImpl the method which accesses the database through the customerDAO object and then we passed the information to the RegisterController classThe Register Controller is the class which connects the View (Java Server Page) with the database and is made of two methods, a GET method and a POST method.(Figure 6.3.3 Register GET Method)The controller needs to have a GET method so that can render the webpage when the customer will access the register page, and a POST method so that the information can be saved into the database when the register button will be submitted. (Figure 6.3.4 Register POST Method)In the POST method we defined as parameter @ModelAttribute (“register”) so that we can make the page responsive and to render the input validation when registering with email and password the commandName = “register” from the Java Server Page called register.jsp Next, in the method we created a Customer object “cust” and we assigned the all the Strings that has to be passed from the View such as email and password. The implementation is quite easy to understand where the information that comes from the View it is taken from the @RequestParam and then assigned to the customer object.In the next line we declared as a String “pass_with_bcrypt” and we assigned the class BCrypt which has the method hashpw, and then we encrypted the password with a salt value. For this part we knew that the register method is working, and looking into Login Table we could see that a new record has been saved into the table and the password was encrypted successfully, having different characters. More information regarding security can be found in the Security Section a bit later.Input Validation Register FormThis part covers one of the most important aspects regarding the Registration part where the user has to input some information and the web page will respond accordingly to what the user inputs inside the textboxes. However, we decided to work on this part after securing the password from the register page, so that we don’t have to come back and debug the errors over and over again.It is a good practice to avoid letting the user to register without typing in the fields, for this approach we used input validation for the Registration part. A common situation is when the user creates a new account, when typing in the email field differently than how an email should be, it will force the user to type a valid email or to create a new email correctly.   In order to validate form fields in Spring Web MVC and to display them in the website the first think that we did was to integrate Bean Validation API and Hibernate Validator in the Customer class. In this class we declared validation constraints on the object models with annotations such as the email field having @NotNull and @Email and for the password field with @Size and a message so that can be displayed on the page. The correct way of integrating Input Validation for Register part can be seen as below:(Figure 6.3.5 Customer Validation)To make them accessible we had to add some dependencies in POM.xml file. This dependencies representing libraries for both Bean Validation API and Hibernate Validator.As we can see in the picture a common situation is when the user enters a password which has a different number than how it is specified in the validation constraints (for example the user cannot type less than 7 characters) then the user will get an error message with red color under the textboxes:  (Figure 6.3.6 Input Validation Register Form)The way of how we integrated input validations was in an easier way because Spring MVC provides full support and minimal configuration. In order to display all errors when the user forgets to input or inputs a different number of characters for password we declared in the RegisterController class, inside the method registerCustomer () with annotation @Valid the model object. Spring MVC will validate the model object annotated by the @Valid annotation after binding its properties when the user will type inside the JSP form. An important role in this method has the class BindingResult where all constraint validations will be exposed as errors through the object of this class. Below we can see how we checked with the help of this object in the if conditional from registerCustomer () method. As if an error has been occurred then the if conditional will redirect on the same page showing all the errors that the user input before and if the user created a valid account with a valid email, then the user will be redirected to Login where he will start accessing the account and start browsing in the website.(Figure 6.3.7 Implementation – Register Validation)While implementing and making input validation working we found some issues. By forgetting and not connecting all parts the right way the page won’t display anything. We looked into each detail and we found that missing one of the libraries or forgetting to put one of the attributes in the JSP page or in the method will make the code not working. The explanation is that in order to make it accessible and fully functional the JSP (Java Server Page) page we had to put the whole form inside the Spring’s form tags. Under each input field we had to declare each input with its own error inside form tags. These are some important steps in order to make these errors visible, without doing this the page won’t display any error and the page will remain blank.(Figure 6.3.8 register.jsp Page)There are two ways of displaying the message: the first one the message will be shown on the webpage when the user doesn’t type or forgets to type in the email or password field. Well, for this approach in the Customer class we declared with annotation @NotEmpty having as parameter (message = “”) as a String where this String represents the message displayed on page.For the second approach in order to display all the errors when typing wrongly inside the fields, we created a file called messages.proprieties and inside the file we specified the content of the error message together with the empty one. This file will be taken as a bean and will be read from the spring-servlet.xml file from where we declared the location. Without specifying this bean, the program won’t know where to find and how to display the errors on page.(Figure 6.3.9 messages. proprieties File)In the sprint 2 we had a smooth development until the 12 of December, when we paused the development because we both had to attend our jobs, so the development has stagnated. However afterwards we had a pretty good productivity and we even managed to finish earlier than expected.(Figure 6.3.10 Burn Down Chart Sprint 2)Sprint RetrospectiveWhat went well?We managed to finish all tasks that we had in the sprint by having a good communication.What could have gone better?Nothing, everything went well after fixing some problems in our code.Any surprises?We have encountered some problems when trying to display input validation for the Register form. When trying to deploy Java program on Tomcat Server and when trying to display the input validations on the page, the program showed us a blank page because there were missing some libraries.Changes needed for the next sprint?There is no need for changes since we managed to find and to solve the problems encountered so far.6.4 Sprint 3In Sprint 3 we developed the Login Page and we tried to moderate the level of time we spent on development, and that’s because we have got used with Spring MVC framework from Java and we wanted to make the best out of the time we have for development.Here is the vision of the Sprint 3:  (Figure 6.4.1 Table Sprint Backlog Sprint 3)When we started with the Login we already had an understanding of how the project will look like and we started off by setting up the Model. After we moved to the DAO class and DAOImpl class where we created the method which will retrieve the information from the database, then we created the Service class and ServiceImpl and afterwards moved to the Controller and JSP file where we created the page and created a method to redirect the url to the. jsp file and created another method which will take the data from the. jsp file that the customer inserts. This one it is taken to the DAOImpl following the road Controller-Service-ServiceImpl-DAO-DAOImpl and it would compare the data inserted by the customer with the data from the DB.We had difficulties at the beginning because we couldn’t manage to retrieve data from the database and it was more confusing since we followed examples found on the web. The problem was that whenever we tried to retrieve the data, the method returned Null Pointer Exception. We tried another approach were we created a method where to extract the information that we needed. In the end we managed to extract data from the Database.Login Method ImplementationThe Login Controller is a class which connects the View, the Java Server Page with database and is made out of two methods, a GET and a POST method.In the GET method we created an empty Customer () object and we passed to the client the page address together with the empty object(Figure 6.4.2 Login GET Method)After the user inputs his details, the user submits the form by pressing the Login button. What happens here is that the POST method is called and we get the Customer object filled with the customer’s details by using @model Attribute in the input Parameter of the method. (Figure 6.4.3 Login POST Method)In this method first we did an if statement where we implemented the input validation for the Login part. Here we check if the customer forgot to type or typed wrong the email or password and in the else conditional we send the customer’s details to the service by using the customerService.isValidCustomer() method. What this does is that it goes to the database with all details and check if there is any record saved with his details. We saved the outcome of the method into a Boolean value called isValid and afterwards we checked if the value is true of false by checking if there is any user with the same credentials as the one that the customer inserted in the Login form. Then the method isValidCustomer () will return true if in fact the password compared from the View is exactly the same as in database, otherwise it will return false.If the Boolean is true, then the method will save the customer’s email in a cookie and the customer will be logged in as long as the Boolean value exists. If the Boolean is true, then the customer will be redirected to the Home Page which in our case is called Index.Secondary if the Boolean returns false the customer will be redirected to the same page, to the Login Page where he will have to input again all details that he inserted in the last session. Together with the view is returned also an error message stating that the credentials that the Customer inserted are not valid.We managed the Login in the Page by using the Cookie. We chose this approach because we are also using in this project Apache Tiles framework. As we mentioned before, Tiles is used for managing all pages in a smarter way, by avoiding repetitive coding for the header and the footer.What we did is that after the customer is logged in, a Cookie is created as long as the cookie is identified in the header.jsp page. What we’ve done here is that we’ve used the <c: if test=””> and in the “test” we made a check for the Cookie. If the cookie exists and is not empty, then a specific view is shown for the header. If not, then the basic view is shown to the user, and by basic I mean the Register and Login buttons in header.The syntax for creating a cookie in java is different from the syntax in C#. However, the basic idea stagnates, meaning that the concept is the same. In Java in order to create a new cookie you will need to create a HttpServletResponse response object. This will process the request and will create the new Cookie. Next we will need to state the name of the cookie and the information we want to store in the cookie. It is possible to store simple values or even objects.As a simple explanation @Cookie Value is commonly used for picking up a Cookie we want to work with. What this will do is that it will find a cookie with its name and It will store the data in an object that we will create. An important thing that needs to be remembered when working with this @CookieValue is that if it is to be used it has to be inserted in the input parameter and it need to have a “defaultValue”. It is very important because if you are to avoid this “defaultValue” then the whole page will send an error If the cookie is empty, or it doesn’t exist. What this defaultValue does is that it does exactly what is says: If the value of the cookie is null or does not exist then the value will be set as the one you’ve set in the defaultValue, this will avoid a lot of errors and it’s more efficient and less time consuming.At the beginning we looked into Sessions and how we could implement into Spring MVC but since in our last project we used this approach, we wanted to do something different and that by using Cookies.However, we looked how to implement and to know in future how to use Sessions in Java. Well, Sessions are somehow similar to those from C# (Visual Studio). At first it seems to be really hard to understand how to create one and to use it in other controllers or in a web pages. As a start we tried to create a session which can be used in a controller as many times as we wanted to. After hours of documentation we did not find anything relevant and since there are so many example out related to Sessions, most of them that we’ve tried didn’t seem to have the expected outcome. However, the implementation is way simpler if we understand the basics. We tried to get to know them but the examples that we found were not quite helpful.Input Validation Login FormBecause the implementation of the Login Form is not that different than the other one from the Registration Form regarding validations we will only mention how we connected the methods and the Java Server Page which in this case is login.jspIt is a good practice to avoid letting the user to log in without typing in the fields, for this approach we used input validation for the Login part. A common situation is when the user logs in without typing, or when the user is typing in the email field differently than how an email should be, it will force the user to type a valid email.  As we can see in the picture a common situation is when the user enters a password which has a different number than how it is specified in the validation constraints (for example the user cannot type less than 7 characters) the user will get an error message with red color under the textboxes:  (Figure 6.4.4 Input Validation Login Form)Looking bellow at the executeLogin () method from the LoginController class we could see that the implementation of the validation for the Login page has been made really easy. In order to display all errors when the user forgets to input or inputs a different number of characters for password we declared in the LoginController class, inside the executeLogin () method with annotation @Valid the model object. Spring MVC will validate the model object annotated by the @Valid annotation after binding its properties when the user will type inside the JSP form. This part takes the same path as for Register when we implemented the input validation.An important role in this method has the class BindingResult where all constraint validations will be exposed as errors through the object of this class. Below we can see how we checked with the help of this object in the if conditional. As if an error has been occurred then the customer will be redirected on the same page showing all the errors that the user input before, and if the user typed a valid account, then the user will be redirected to Index page where he will start browsing in the website.(Figure 6.4.5 Implementation – Log in Validation)Here can be seen how we made the page showing the errors when the user forgets or does not input inside the text boxes through the commandName= ”cust”(Figure 6.4.6 login.jsp Page)Spring MVC SecurityWe decided for our security to work and use as in the previous semester, the same algorithm BCrypt that helps making password cracking harder. First we looked into Spring MVC Security, into some examples since our project is based on Spring MVC, we looked into how to integrate and how this one can be a solution for Securing our Web Application better. For this part we tried two approaches, the first one using the Spring MVC Security provided by the framework and for the second one by using an open source example in Java from GitHub. For the first approach looking at all examples it was quite easy to understand but the implementation was quite hard to be done. The reason is that Spring MVC Security uses an external file called security-config.xml which has a specific section where the password can be decoded. We looked and tried to understand the basic idea and how a simple SQL query from such file can decode the password. Since all examples that we found from the internet have authentication for both User and Admin we tried to use and implement the code in the same way and later on to change only for user role since this Web Application is made only for Users.(Figure 6.4.7 Spring MVC Security security-config.xml file)So, after we tried to change the username – parameter into another variable having another name and after seeing that xml file complained having some errors we came to a conclusion that this file cannot be changed really easy. We looked into and tried to search why this file had some errors. Afterwards we found that these variables are part of Spring MVC and these cannot be changed with other names, and where only the parameters can be adjusted to our name conventions.  Then we changed for username – parameter into email and the password – parameter into password. The implementation looked quite simple where in the RegisterController class in the POST method we have put into a string the encrypted method and then set for the password. The register part was really easy to implement and as a result we could see in the database that the password has been encrypted with a salt value successfully. Every time when the database is accessed the password will have the same prefix but a different salt value.In order to encrypt the password with BCrypt we had to define in the spring-servlet.xml file the bean for this class so that the framework can make it accessible. If this bean is not defined than the Java program will complain that the bean of this library is missing. Everything went well until we started to work on the Login part where we had to compare the password that the user input with the password that was initially encrypted with salt value at the beginning when the user registered with his email and his password.In this part we described exactly how passwords should be encrypted and how they should be integrated into Spring MVC Framework. We found to be quite hard to decode the password because in the Java Server Page, in our page login.jsp we had to use inside the form a different action, different than what we used before, such as a simple “/” representing the path that the POST method will take when the login button will be submitted. (Figure 6.4.8 Spring MVC Security action form)This action was really hard to understand and how can check that the password that the user input in the login page can check the password encoded from the database. As a result, every time when we tried to run the program, Java complained that the URL path does not exist therefore it could not redirect to the index page.We came to the conclusion the we spent too much time in implementing and trying to figure it out how make it work, so we looked into another way of how to secure our password, and we found an example in GitHub, an open source code written in Java, and this one would not make our process as complicated as before. This class BCrypt has all the methods that we need to encode and decode the password. This approach helped us to understand how all the methods are connected and how all these algorithms are working.What we did here is that we created a package called encryption and inside a Java class called BCrypt. In this class we used the method checkpw () of type Boolean so that we can find a match between password encrypted in the register and the password that the user input in the login page. (Figure 6.4.9 checkpw() method from BCrypt  )So we created a method in dao package called isValid of type Boolean and this method what it does is that checks if the email and the password that the user input in the Java Server Page, which in our case is login.jsp page is the same with the password that is stored in the database.This method has the implementation in the CustomerDAOImpl class and it can be seen as bellow:(Figure 6.4.10 isValid () Method from CustomerDAOImpl)What exactly has this method is a SELECT query where it checks in the Login table if there’s a unique email in the table and then retrieve only one record since we made the condition to limit the records to 1. Then, we created a Customer object called customer and in the while loop we tried to retrieve from the database the password so that we compare if the password that is written in the View page is the same with the password from the database.Outside of the while loop we created a variable check of type Boolean and this one checks the password from the view if is the same with that one from the database which was created earlier in the register.jsp page. This Boolean checks the password that was encrypted initially with a salt value with that one from the login.jsp page. Since our method is of type Boolean the method will return true or false based on the comparison of these passwords.The salt has to be unique per-user per password. Every time when a user creates a new account or changes his password, the password has to be hashed with a new random salt. In order to store a password, we need to generate a long random salt and to save both the salt and hash in the user’s database record.In order to validate a password, we need to retrieve the user’s salt and hash from the database. Then prepend the salt to the given password and hash with the same hashing function. The last thing is to compare the hash of the given password with the hash from the database. If we have a match, then the password is correct.Why do we hash passwords?Is because users are entering their passwords into the website. They trust developers with their security when created the website. For example, if a database gets hacked and all user’s passwords are unprotected, then malicious hackers can use those passwords to compromise user’s account on other websites and services. This a known situation when people in general use the same password everywhere. Here is nothing than user’s security risk which no one is responsible than developer who’s in charge with the website.(Figure 6.4.11 Burn Down Chart Sprint 3)In sprint 3 we had a linear development, our jobs didn’t get involved in our development anymore and we managed to keep up our development with the expected productivity one again.Sprint RetrospectiveWhat went well?We managed to finish all tasks that we had in the sprint by having a good communication.What could have gone better?Nothing, everything went well after fixing some errors with validations for the Login part in our code.Any surprises?We have encountered some problems while trying to login into the page. While the validation part of the Login Form didn’t work we had some errors in Console where Java complained that the password cannot be compared with the method from the BCrypt class.  Changes needed for the next sprint?There is no need for changes since we managed to solve the problem with the validation by doing a small change inside the executeLogin () method. 6.5 Sprint 4In this Sprint we developed the page that customers can use in order to get products and reviews. This objective was rated in Sprint 1. (Figure 6.5.1 Table Sprint Backlog Sprint 4)After finishing with the method for retrieving and displaying data to the UI we have identified something unexpected. When we tried to refresh the page, a message popped up on the page saying “Confirm Form Resubmission”. This was not a problem but more an inconvenience since we didn’t want to show in our page this error every time when the user will press the refresh button. After doing some research regarding this error we found that we can easily get rid of this error by following the “POST-Redirect-Get Pattern”.After reading documentation about this error we modified the structure of the method in the SearchController class. As our approach we took data required from the customer and stored it into a Cookie when the customer submitted the form. Afterwards, we redirected the user to the same page every time when the button refresh is submitted. The page is being processed through the GET method and will return the page. However, since we tried to achieve the Post-Redirect-Get Pattern we moved the functionality from the POST Method to the GET Method.We also added to the method a check for the cookie that we created in the previous POST Method. I am taking the cookie by requesting the @CookieValue in the input Parameter which will get the Cookie value. We have set up the @CookieValue to have a default value so that the page will not sent and Error, by doing this whenever the cookie is null, the @Cookie Value will be set as the default String that we are setting.In the method we created an if statement which checks if the value of the cookie is the default on. If not the data from the cookie is used to return data to the User, at the same time it clears the Cookie and return the View to the Customer. By doing this we manage to hit refresh button as many times as we want and the form will successfully refresh and no more notifications will pop up, and by doing this we managed to achieve the Post-Redirect Get PatternSearch Functionality(Figure 6.5.2 Search POST Method)In the POST method of the SearchController class we request a few parameters few from the page which represent the search String that the customer will insert in the search box in order to receive data from the page. After receiving the requested parameters from the page, we store this values in sessions so that we can reuse them in the GET method of the page. The reason why we don’t process all of the functionality in the POST method is because we are using only one page for data processing and displaying. Therefore, we use the post-redirect-get architecture in order to ensure a positive flow. After we set up the sessions we redirect the user to the same page and that one being search page.(Figure 6.5.3 Search GET Method)We sent a Customer object to the jsp page which is empty and the purpose of this object is that it will be called back when the POST method is called and all the data inserted in by the customer can be seen the customer object.Then we created 2 string values which both contains a session that was created initially in the POST method. When the customer comes for the first time on the page, the sessions will be null, however after the post method is called the page will redirect to get method after the redirect and the sessions will have information and they will be usable.(Figure 6.5.4 Search GET Method Part 2)In this lines of code, we check if the session is null or empty and in the first phase the session will be null so nothing will happen but in the redirect phase the process will pass over this if statement.We create an Array List of Product which contains objects and we call the getProducts method from the ProductService class and we pass the data from the SessionE String that we created previously.What we want to do Is that we want to retrieve a list of products based on the string that the customer inserted in the search box.What happens is that the request goes to the ProductService interface which will call the ProductDAO interface which will call the ProductDaoImpl class and then will extract data from the database and afterwards return an Array List of Product object back to the ProductDAO and which will send the list to the ProductService and the ProductService class will return the list to the SearchController.(Figure 6.5.5 getProducts () Method)What we do here is that we set up a query which will retrieve data about products based on the String inputted by the customer. We then do a while loop from which we take the data from the database row by row and we insert it into an Array List. When the loop is done we return the list to the SearchController.Coming back to the SearchController class, after we get the list we check if the list is empty or not. If it is empty, we send an object to the page with an error String and before returning the page we delete the sessions so that the sessions will not pass through the if statement.(Figure 6.5.6 Search GET Method Part 3)If the productList object of the ArrayList of Product is not empty, we call the getAsin () method from the SearchController to return a list of asin values which is unique for each product in the ArrayList of Product. The we pass to the getAsin () method the ArrayList of Product.(Figure 6.5.7 getAsin () Method)In the getAsin () method we extract the asin value for each product and then return the method. The reason why we want to do this is because we want to use this unique value to return a list of reviews specific to each product. Afterwards, we call the getReviews () method from the ReviewService class and we pass the String Arraylist containing asin value for each product.(Figure 6.5.8 getReviews () Method Part 1)In the ReviewDAOImpl class we created the method getReviews () which contains a key and a value. We decided to store the asin as a key which will represent the object and as the value we will store the review. By doing this we can later on extract each review by comparing the key with each product and then extract in an ordered manner each review.We have implemented a for loop and we looped through the productAsin list that we get from the controller. What happens afterwards is that we created a string value which stored the asin value from the list. We wanted to loop trough the list so that we can get all the reviews for each product.(Figure 6.5.9 getReviews () Method Part 2)After we have the data we then do a while loop and insert each record from the database in a review object which has specific data that we are expecting to extract. After we fill in a object with data we add it to the Array List reviewList which holds reviews objects. After we have gathered all the reviews for the specific asin we do a loop in which we set up reviews and asin in the mapReviews Map.One thing that is to be mentioned is that while working with the JsonParser class we had issues with inserting the data in the Database. What we did is that we added extra columns to the Review table and we stored in them data relevant to our needs. When we process the reviews and come back with a score, we try and update the Review Table in MySQL and it is successful however the response time it really slow, more exactly for 10.000 records on update it would require 30 minutes to update the rows.This was an issue we had to fix and what we did is that we tried to update the executeBatch in such a way that It would improve the response time. It was unsuccessful and because of this we decided to take a different approach. We decided to create a new table called Score in which we set up the table to take data relevant to the score. We then executeBatch on inserting the data in the score table and the data is inserted within minutes.(Figure 6.5.10 SQL Query for Retrieving Score in the Page)We then needed to optimize the query which we use in order to extract reviews. What we do is that we use the inner join in order to get the data from both the tables. We specify what we want from both tables and then we two conditions base on which the data should be returned.We have encountered a bug where by having just one condition, the reviews would return duplicated and by having two conditions the problem was fixed. The reason why we encountered this error is because by only specifying the review.asin / score.asinProduct both values are duplicated and in order to avoid this we passed another condition so that we could have a unique way of identifying the rows between the tables.(Figure 6.5.11 search.jsp Page Part 1)In the search.jsp page we have sent from the controller a list of products which are accessible through the string products. What we do in the “c: if” is that we check if the product list is empty, if the list is empty the page will display a message which will inform the customer that there are no products for that group of words that the customer searched.We wanted to make a special function for users who are not logged in. Initially we thought of not showing the search option if the customer is not logged in and instead show some other content.We didn’t like the idea since the approach was not appealing to our purpose, we wanted users to see what the page can do for them instead of not showing them anything relevant.We came up with another idea, we decided to limit the amount of products that the page will display to the user. So what we did is that we checked if the session is null and then we checked if the list is empty or not based on the string that the customer inserted. We limited the search to 3 products, and what the “c: forEach” will do for us is that it will take the list and it will loop 3 times through it and then stop and show the content to the userAfterwards we created specific html views for the products and the reviews.(Figure 6.5.12 search.jsp Page Part 2)In this part we make a loop which will create a html object for each value in map. We check to see if the map has values, if not there will be displayed a message to the customer informing him that no review was found.We check trough a “c: if” the map is not empty, if it is not then we create another “c: if” where we check if the product that is currently on the loop has the same asin with the first review from the Map. If not, then it will skip to the next review and it prints only the reviews which have the same asin as the product.For each review we have set a specific view in which the details will be shown.(Figure 6.5.13 search.jsp Page Part 3)In sprint 4 we a linear development until the 25th of December when we both took a day off since it was Christmas and we both wanted to take the time and spend it with the family and friends. Afterwards we started the development we have had a few problems with the SearchController Class. The problem originated from the approach that we decided to take on when returning to the customer with data that he required. The problem is that upon refreshing the page the data would still be displayed to the customer. We took a step back and reflected on the situation and we decided to follow a different(Figure 6.5.14 Burn Down Chart Sprint 4)Sprint RetrospectiveWhat went well?We managed to keep on track with the expected development process even though we came across a problem which we were not familiar with, architectural speaking. We however identified the problem and after we did research we managed to find a way to overcome the impediment.We held a Scrum Meeting on a daily basis which helped us to keep tracking of what is going on.What could have gone better?We didn’t identify any flows in the development process while in this sprint, we could even say that we managed to keep on track with development even though we had a day off.Any surprises?We were not expecting the architectural flow that we had in the project, we were lucky to identify the bug and managed to fix it.6.6 Sprint 5In the 5th Sprint we were focused on adding extra features to the page, were the customer could customize the way in which data is being shown to them by choosing a category.Here is the vision of the Sprint 5:(Figure 6.6.1 Product Backlog Sprint 5)Functionality(Figure 6.6.2 Search POST Method)In the POST method of the SearchController class we request a few parameters few from the page which represent the search String that the customer will insert in the search box in order to receive data from the page. After receiving the requested parameters from the page, we store this values in sessions so that we can reuse them in the GET method of the page. The reason why we don’t process all of the functionality in the POST method is because we are using only one page for data processing and displaying. Therefore, we use the post-redirect-get architecture in order to ensure a positive flow. After we set up the sessions we redirect the user to the same page and that one being search page.(Figure 6.6.3 Search GET Method)In the GET method of the page we created a Map object called category in which we put data relevant to this object and then we add this object to the ModelAndView library an object called model. What happens here is that by adding this map object to the model object, we are sending the map object to the Java Server Page which in this case is search.jsp page and there we use the object by referring to the title set while adding the object. The category object will represent the category in which the data can be extracted, this will later be used in the getReviews () method from the ReviewService class.(Figure 6.6.4 getReviews () Method)In the GET method from SearchController class we’ve created an object and sent it to the search.jsp page. That object was called category. Now it is time to use that object, we do this by making a switch. By having categories, each category return a specific value associated with the category. The first values is the basic value which will return at all times, unless another value is selected for the category, the basic value is “none”. When a category is selected it is saved in a session and picked up in get and sent to this method, here we switch based on the string value.In sprint 5 we kept the expected productivity up to date, even though we had a day off from development.(Figure 6.6.5 Burn Down Chart Sprint 5)Sprint RetrospectiveWhat went well?The development process was kept at a constant pace which is something that we were at most pleased with.We held a Scrum Meeting on a daily basis which helped us to keep tracking of what is going on.What could have gone better?We didn’t identify any flows in the development process while in this sprint, we could even say that we managed to keep on track with development even though we had a day off.Any surprises?This part of the project went just as planned, we didn’t identify any unexpected outcomes Learning Outcomes & Future WorkIn this section, we will describe the learning outcomes of our project, and our achievement with respect to the learning goals. In addition, we will present our reflections on what we have learned in this project. Finally, we will outline our future work.We have defined several learning goals in the beginning of the project. After all the work that we did, we would like to mention all the goals that we achieved together with some new goals that we want to integrate into our project.The current goals that we achieved successfully are listed as follows:Created a Web Application using Spring MVC FrameworkIntegrated Apache Tiles an open-source template framework for modern Java applicationsGave alternatives for user in querying data such as ability to search for different categoriesAdded a level of security to Register and Log in within the webpage.Used Query optimization within the database for better search results.During the implementation of our project, a lot of additional ideas have emerged. We have found that we could improve several parts in our Web Application, such as: adding a better layout (CSS) for all pages, together with some functions by using JavaScript. We could also use some graphical effects for all pages but we are aware that all pages will not be as responsive as when using a simple and clean layout. Therefore, we believe that graphics (e.g., GIF images or videos) will affect the performance and the response time in searching for different products.In the future, we would like to improve different aspects in our project. First, we would like to improve our current analysis method by employing the analysis model provided by Apache Lucene. Moreover, we would like to also incorporate Apache Lucene search functionality to allow users to retrieve and rank comments. Apache Lucene is a full text search library in Java which makes it easy to add search functionality to an application or a website. The core technology is indexing, which allow full-text search on a document collection, e.g., news articles, web pages or product reviews. It also provides query language and interface that can be easily integrated into our current project. To this end, we plan to implement a ranking method by taking into consideration review scores that we have already implemented in our current implementation. As a goal for our future work, we aim to achieve a fast search functionality that enables users to perform querying of reviews and supports them to make smart decision about online product purchase.While planning the functionality of the project we also took in consideration testing. We intended to use Junit Test in order to check if the methods are working as expected. However, we also took in consideration the time needed in order to build this test classes and we were uncertain if we can keep up with the development if we were to create Junit Tests for each method. So we decided to take a different approach in this project, meaning that we decided to do the testing manually. This is not an appropriate approach however, since Dacian was in the internship until the mid of December, our time was limited and we needed to use it wisely. We did not find this approach favorable, since we acknowledged the importance of Junit Test, however we had to take this decision in order to make sure that the development process will be up to the expected development process. For future work we plan to integrate and implement in our project Junit Tests for a number of methods together with some small changes in the UI.ConclusionsIn our project, data we are using is taken from different Json files, which we read and migrate into our database, this approach is made because we don’t have access to a Server from which we can take data whenever we please. However, if we were to have access to a server we would be able to take data whenever we want, and our approach on implementing the functionality would have been changed.We would first connect to a public API, the Amazon API, from where we would collect data by using a Crawler and then we would take separately the reviews and put them into a collection so that we can process them later into JSON, XML or HTML format. This part will cover the preprocess module where the information collected from Amazon will be stored in the database. The information will be analyzed using the same approach that we have used in our project. Based on the analyzation made of dictionary words of positive and negative words a score will be aggregated for each review and afterwards stored in the database. After the analyze has been done, we would display the data to the customer in the same way as how we did in our project where the approach would not be different at all.By storing all reviews and scores in the database the response time when querying for a product would be fast among a huge database of products and reviews. And since we have a category system implemented where the customer can choose to retrieve from the database on different criteria, the response time could be slower because of all the processing that it has to do.Appendixhttp://howtodoinjava.com/spring/spring-mvc/spring-mvc-hello-world-example/ Extending Bootstrap, Christopher Niska,2014http://www.lucenetutorial.com/basic-concepts.html\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Collecting Data from JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest solution for reading data from JSON files in Python is by using requests and JSON library provided by Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json from 'https://quotes.rest/qod.json'\n",
    "r = requests.get('https://quotes.rest/qod.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the result into dictionary\n",
    "res = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": {\n",
      "        \"total\": 1\n",
      "    },\n",
      "    \"contents\": {\n",
      "        \"quotes\": [\n",
      "            {\n",
      "                \"quote\": \"When you win, say nothing. When you lose, say less.\",\n",
      "                \"length\": \"51\",\n",
      "                \"author\": \"Paul Brown\",\n",
      "                \"tags\": [\n",
      "                    \"inspire\",\n",
      "                    \"losing\",\n",
      "                    \"running\",\n",
      "                    \"tod\",\n",
      "                    \"winning\"\n",
      "                ],\n",
      "                \"category\": \"inspire\",\n",
      "                \"date\": \"2019-09-19\",\n",
      "                \"permalink\": \"https://theysaidso.com/quote/paul-brown-when-you-win-say-nothing-when-you-lose-say-less\",\n",
      "                \"title\": \"Inspiring Quote of the day\",\n",
      "                \"background\": \"https://theysaidso.com/img/bgs/man_on_the_mountain.jpg\",\n",
      "                \"id\": \"3dlKxoNAOZsB__Nb61H95weF\"\n",
      "            }\n",
      "        ],\n",
      "        \"copyright\": \"2017-19 theysaidso.com\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# check json structure\n",
    "print(json.dumps(res, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract contents\n",
    "q = res['contents']['quotes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': 'When you win, say nothing. When you lose, say less.',\n",
       " 'length': '51',\n",
       " 'author': 'Paul Brown',\n",
       " 'tags': ['inspire', 'losing', 'running', 'tod', 'winning'],\n",
       " 'category': 'inspire',\n",
       " 'date': '2019-09-19',\n",
       " 'permalink': 'https://theysaidso.com/quote/paul-brown-when-you-win-say-nothing-when-you-lose-say-less',\n",
       " 'title': 'Inspiring Quote of the day',\n",
       " 'background': 'https://theysaidso.com/img/bgs/man_on_the_mountain.jpg',\n",
       " 'id': '3dlKxoNAOZsB__Nb61H95weF'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print output\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you win, say nothing. When you lose, say less. \n",
      "-- Paul Brown\n"
     ]
    }
   ],
   "source": [
    "# extract quote and author\n",
    "print(q['quote'], '\\n--', q['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Collecting Data from HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will take a look into how to collect data from HTML pages. As a solution we will make use of bs4 library also known as BeautifulSoup in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /home/dacy/.local/lib/python3.6/site-packages (0.0.1)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/lib/python3/dist-packages (from bs4) (4.6.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install required library\n",
    "!pip3 install bs4 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import urllib.request as urllib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch html file (e.g Wikipedia)\n",
    "response = urllib.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data into html_doc (binary)\n",
    "html_doc = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse html file\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the parsed html file\n",
    "strhtml = soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Natural language processing - Wikipedia\n",
      "  </title>\n",
      "  <script>\n",
      "   document.documentElement.className=\"client-js\";RLCONF={\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":!1,\"wgNamespaceNumber\":0,\"wgPageName\":\"Natural_language_processing\",\"wgTitle\":\"Natural language processing\",\"wgCurRevisionId\":915734112,\"wgRevisionId\":915734112,\"wgArticleId\":21652,\"wgIsArticle\":!0,\"wgIsRedirect\":!1,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Webarchive template wayback links\",\"All accuracy disputes\",\"Articles with disputed statements from June 2018\",\"Wikipedia articles with LCCN identifiers\",\"Wikipedia articles with NDL identifiers\",\"Natural language processing\",\"Computational linguistics\",\"Speech recognition\",\"Computational fields of study\",\"Artificial intelligence\"],\"wgBreakFrames\":!1,\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgSeparator\n"
     ]
    }
   ],
   "source": [
    "# print few lines\n",
    "print(strhtml[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Natural language processing - Wikipedia</title>\n"
     ]
    }
   ],
   "source": [
    "# extract tag values\n",
    "# 1. extract title\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# 2. extract content between the following tags: <title> </title>\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 3. extract content between the following tags: <a> </a>\n",
    "print(soup.a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n"
     ]
    }
   ],
   "source": [
    "# 4. extract content between the following tags: <b> </b>\n",
    "print(soup.b.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all instances of a particular tag (e.g 'a')\n",
    "content_tag_a = []\n",
    "for x in soup.find_all('a'):\n",
    "    content_tag_a.append(x.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 'Jump to navigation',\n",
       " 'Jump to search',\n",
       " 'Neuro-linguistic programming',\n",
       " 'Language processing in the brain']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 occurencies \n",
    "content_tag_a[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all text of a particular tag\n",
    "content_tag_p = []\n",
    "for x in soup.find_all('p'):\n",
    "    content_tag_p.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not to be confused with Non-linear programming (also NLP)',\n",
       " 'Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\\n',\n",
       " 'Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\\n',\n",
       " 'The history of natural language processing (NLP) generally started in the 1950s, although work can be found from earlier periods.\\nIn 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence.\\n',\n",
       " 'The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.[2]  However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.  Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\\n']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 occurencies\n",
    "content_tag_p[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Parsing text using Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will take a look into how regular expressions are helpful when dealing with text data. This is very much required when dealing with raw data from the web, which would contain HTML tags, long text, repeated text.\n",
    "\n",
    "For this we will make use of the \"re\" library written in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic flags in \"re\" library are:\n",
    "- re.I : used for ignoring casing\n",
    "- re.L : used for finding a local dependent\n",
    "- re.M : used for finding patterns throughout multiple lines\n",
    "- re.S : used to find dot matches\n",
    "- re.U : used to work for unicode data\n",
    "- re.X : used for writing regex in a more readable format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expression's functionality:\n",
    "- Find the single occurence of character a and b: \n",
    "Regex: [ab]\n",
    "- Find characters except for a and b:\n",
    "Regex: [^ab]\n",
    "- Find the character range of a to z:\n",
    "Regex: [a-z]\n",
    "- Find a range except to z:\n",
    "Regex: [^a-z]\n",
    "- Find all the characters a to z as well A to Z:\n",
    "Regex: [a-zA-Z]\n",
    "- Any single character:\n",
    "Regex:\n",
    "- Any whitespace character:\n",
    "Regex: \\s\n",
    "- Any non-whitespace character:\n",
    "Regex: \\S\n",
    "- Any digit:\n",
    "Regex: \\d\n",
    "- Any non-digit:\n",
    "Regex: \\D\n",
    "- Any words:\n",
    "Regex: \\w\n",
    "- Any non-words:\n",
    "Regex: \\W\n",
    "- Either match a or b:\n",
    "Regex: (a|b)\n",
    "- The occurence of a is either zero or one:\n",
    "    - Matches zero or one occurence but not more than one occurence\n",
    "    Regex: a? ; ?\n",
    "    - The occurence of a is zero times or more than that:\n",
    "    Regex: a* ; * matches zero or more than that\n",
    "    - The occurence of a is one time or more than that:\n",
    "    Regex: a+ ; + matches occurences one or more that one time\n",
    "\n",
    "Exactly match three occurences of a:\n",
    "Regex: a{3}\n",
    "\n",
    "Match simultaneous occurences of a with 3 or more than 3:\n",
    "Regex: a{3,}\n",
    "\n",
    "Match simultaneous occurences of a between 3 to 6:\n",
    "Regex: a{3,6}\n",
    "\n",
    "Starting of the string:\n",
    "Regex: ^\n",
    "\n",
    "Ending of the string:\n",
    "Regex: $\n",
    "\n",
    "Match word boundary:\n",
    "Regex: \\b\n",
    "\n",
    "Non-word boundary:\n",
    "Regex: \\B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most used functions are as follows: re.match() and re.search() and they are used to find patterns, and they can be processed according to the requirements of the application\n",
    "\n",
    "- re.match() function checks for a match of the string only at the beginning of the string\n",
    "                      if it finds the pattern at the beginning of the input string then it\n",
    "                      return matched pattern; else it returns a noun\n",
    "- re.search() function checks for a match of the string anywhere in the string. It finds all\n",
    "                      the occurences of the pattern in the given input string or data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the process of splitting the sentence into chunk of words. One way to do this is by using re.split function from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'like', 'this', 'book.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the split query\n",
    "re.split('\\s+', 'I like this book.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting email IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to do this is by using re.findall function from Python \"re\" library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. read / create the document or sentences\n",
    "doc = \"For more details please mail us at: xyz@abc.com, pqr@mno.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 execute the re.findall function\n",
    "addresses = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xyz@abc.com\n",
      "pqr@mno.com\n"
     ]
    }
   ],
   "source": [
    "for address in addresses:\n",
    "    print(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing email IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we replace  email ids from sentences or documents with another email id. The simplest way to do this is by using re.sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. read / create the document or sentences\n",
    "doc = \"For more details please mail us at xyz@abc.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. execute re.sub function\n",
    "new_doc = re.sub(r'([\\w\\.-]+)@([\\w\\.-]+)', r'pqr@mno.com', doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For more details please mail us at pqr@mno.com'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data from ebook and perform regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import re\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url that we want to extract information\n",
    "url = 'https://www.gutenberg.org/files/2638/2638-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to extract\n",
    "def get_book(url):\n",
    "    # send a http request to get the text from project Gutenberg\n",
    "    raw_text = requests.get(url).text\n",
    "    \n",
    "    # skip metadata from the beginning of the book\n",
    "    start = re.search(r\"\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK .* \\*\\*\\*\", raw_text).end()\n",
    "    \n",
    "    # skip metadata from the end of the book\n",
    "    end = re.search(r\"II\", raw_text).start()\n",
    "    \n",
    "    # keep relevant text\n",
    "    text = raw_text[start:end]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def preprocess(sentence):\n",
    "    return re.sub('[^A-Za-z0-9.]+', ' ', sentence).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = get_book(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing\n",
    "processed_book = preprocess(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' produced by martin adamson david widger with corrections by andrew sly the idiot by fyodor dostoyevsky translated by eva martin part i i. towards the end of november during a thaw at nine o clock one morning a train on the warsaw and petersburg railway was approaching the latter city at full speed. the morning was so damp and misty that it was only with great difficulty that the day succeeded in breaking and it was impossible to distinguish anything more than a few yards away from the carriage windows. some of the passengers by this particular train were returning from abroad but the third class carriages were the best filled chiefly with insignificant persons of various occupations and degrees picked up at the different stations nearer town. all of them seemed weary and most of them had sleepy eyes and a shivering expression while their complexions generally appeared to have taken on the colour of the fog outside. when day dawned two passengers in one of the third class carriages found themselves opposite each other. both were young fellows both were rather poorly dressed both had remarkable faces and both were evidently anxious to start a conversation. if they had but known why at this particular moment they were both remarkable persons they would undoubtedly have wondered at the strange chance which had set them down opposite to one another in a third class carriage of the warsaw railway company. one of them was a young fellow of about twenty seven not tall with black curling hair and small grey fiery eyes. his nose was broad and flat and he had high cheek bones his thin lips were constantly compressed into an impudent ironical it might almost be called a malicious smile but his forehead was high and well formed and atoned for a good deal of the ugliness of the lower part of his face. a special feature of this physiognomy was its death like pallor which gave to the whole man an indescribably emaciated appearance in spite of his hard look and at the same time a s'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_book[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform exploratory data analysis on data using regex\n",
    "# Count number of times \"the\" is appeared in the book\n",
    "len(re.findall(r'the', processed_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"i\" with \"I\"\n",
    "processed_book = re.sub(r'\\si\\s', \" I \", processed_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' produced by martin adamson david widger with corrections by andrew sly the idiot by fyodor dostoyevsky translated by eva martin part I i. towards the end of november during a thaw at nine o clock one morning a train on the warsaw and petersburg railway was approaching the latter city at full speed. the morning was so damp and misty that it was only with great difficulty that the day succeeded in breaking and it was impossible to distinguish anything more than a few yards away from the carriage windows. some of the passengers by this particular train were returning from abroad but the third class carriages were the best filled chiefly with insignificant persons of various occupations and degrees picked up at the different stations nearer town. all of them seemed weary and most of them had sleepy eyes and a shivering expression while their complexions generally appeared to have taken on the colour of the fog outside. when day dawned two passengers in one of the third class carriages found themselves opposite each other. both were young fellows both were rather poorly dressed both had remarkable faces and both were evidently anxious to start a conversation. if they had but known why at this particular moment they were both remarkable persons they would undoubtedly have wondered at the strange chance which had set them down opposite to one another in a third class carriage of the warsaw railway company. one of them was a young fellow of about twenty seven not tall with black curling hair and small grey fiery eyes. his nose was broad and flat and he had high cheek bones his thin lips were constantly compressed into an impudent ironical it might almost be called a malicious smile but his forehead was high and well formed and atoned for a good deal of the ugliness of the lower part of his face. a special feature of this physiognomy was its death like pallor which gave to the whole man an indescribably emaciated appearance in spite of his hard look and at the same time a s'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_book[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ironical--it',\n",
       " 'malicious--smile',\n",
       " 'fur--or',\n",
       " 'astrachan--overcoat',\n",
       " 'it--the',\n",
       " 'Italy--was',\n",
       " 'malady--a',\n",
       " 'money--and',\n",
       " 'little--to',\n",
       " 'No--Mr',\n",
       " 'is--where',\n",
       " 'I--I',\n",
       " 'I--',\n",
       " '--though',\n",
       " 'crime--we',\n",
       " 'or--judge',\n",
       " 'gaiters--still',\n",
       " '--if',\n",
       " 'through--well',\n",
       " 'say--through',\n",
       " 'however--and',\n",
       " 'Epanchin--oh',\n",
       " 'too--at',\n",
       " 'was--and',\n",
       " 'Andreevitch--that',\n",
       " 'everyone--that',\n",
       " 'reduce--or',\n",
       " 'raise--to',\n",
       " 'listen--and',\n",
       " 'history--but',\n",
       " 'individual--one',\n",
       " 'yes--I',\n",
       " 'but--',\n",
       " 't--not',\n",
       " 'me--then',\n",
       " 'perhaps--',\n",
       " 'Yes--those',\n",
       " 'me--is',\n",
       " 'servility--if',\n",
       " 'Rogojin--hereditary',\n",
       " 'citizen--who',\n",
       " 'least--goodness',\n",
       " 'memory--but',\n",
       " 'latter--since',\n",
       " 'Rogojin--hung',\n",
       " 'him--I',\n",
       " 'anything--she',\n",
       " 'old--and',\n",
       " 'you--scarecrow',\n",
       " 'certainly--certainly',\n",
       " 'father--I',\n",
       " 'Barashkoff--I',\n",
       " 'see--and',\n",
       " 'everything--Lebedeff',\n",
       " 'about--he',\n",
       " 'now--I',\n",
       " 'Lihachof--',\n",
       " 'Zaleshoff--looking',\n",
       " 'old--fifty',\n",
       " 'so--and',\n",
       " 'this--do',\n",
       " 'day--not',\n",
       " 'that--',\n",
       " 'do--by',\n",
       " 'know--my',\n",
       " 'illness--I',\n",
       " 'well--here',\n",
       " 'fellow--you']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all occurances of text in the format \"abc--xyz\"\n",
    "re.findall(r'[a-zA-Z0-9]*--[a-zA-Z0-9]*', book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
